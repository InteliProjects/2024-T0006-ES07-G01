# Artefatos

Coloque aqui a localização dos artefatos entregues em cada sprint (o link para o artefato), ou então preencha diretamente neste markdown.

Veja as instruções e maiores detalhes sobre os artefatos na Adalove.

## Visão Geral do Projeto

Este projeto, conduzido em parceria com a Samba Mobile Multimídia S/A, visa ajuda-los no gerenciamento de vídeos utilizando inteligência artificial. Reconhecendo a necessidade de entender e classificar vídeos em plataformas de streaming, o projeto propõe o desenvolvimento de uma solução inovadora de IA. Esta solução será capaz de analisar detalhadamente o conteúdo dos vídeos, criar tags e categoriza-los e possivelmente no futuro cruzar essa informação com dados analíticos de consumo, com o objetivo de extrair insights significativos sobre engajamento. Tais insights serão fundamentais para orientar nossos clientes na otimização de conteúdo, visando maximizar a retenção de usuários e o engajamento. 
Ao alcançar os objetivos delineados, esperamos fornecer uma ferramenta valiosa para a Samba Mobile Multimídia S/A e seus clientes, capacitando-os a se destacarem em um mercado competitivo através de estratégias de conteúdo informadas por dados.

## Parceiro de Negócios

A Samba Mobile Multimídia S/A, nosso parceiro de negócios, tem se estabelecido como uma força disruptiva e audaciosa no mercado de multimídia há mais de 18 anos. A empresa é conhecida por sua capacidade de co-criar negócios duradouros, impulsionando eficiência, crescimento financeiro e uma cultura alinhada com as rápidas mudanças do mercado. Com um espírito questionador, a Samba busca constantemente novos caminhos para alcançar resultados significativos, desafiando convenções e promovendo a inovação. Hoje a empresa atua no segmento de Serviços de Hospedagem e Distribuição de Vídeo para Empresas junto com outras empresas como Youtube, Brightcove e Wistia.

## Descritivo da Solução

Nossa solução será um Microsaas a ser usado por empresas que atuam no segmento de Serviços de Hospedagem e Distribuição de Vídeo, esse serviço será usado para criar tags, palavras chaves e categorizar vídeos dentro da sua plataforma. Visando solucionar as dores dos seus clientes, que possuem muitos vídeos em sua conta e não conseguem localizar e fazer uma boa gestão das suas publicações.


# Sprint 1

## Entendimento de Negócios

Nesse capítulo de negócios, exploraremos a proposta de valor da nossa solução por meio da matriz oceano azul, identificando oito atributos cruciais para os clientes. Apresentamos também a matriz de riscos, que antecipa desafios e oportunidades, enquanto o Canvas proposta de valor mapeia dores e ganhos da solução. 
Quando falamos sobre o financeiros, mostramos os investimentos planejados e projeções de custos, feitos a partir de uma lógica sólida. Este capítulo não apenas mapeia estratégias, mas determina as bases para a inovação e sucesso no cenário competitivo da análise de perfil de consumo de vídeos com a nossa inteligência artificial.


## Matriz de riscos 

<img width="1148" alt="Captura de Tela 2024-02-16 às 18 46 07" src="https://github.com/Inteli-College/2024-T0006-ES07-G01/assets/99424901/178f14fe-39ff-4a7d-8752-4ed3c9fe0fd5">



Oportunidades :

Disponibilidade de um grande volume de dados: A existência de uma grande quantidade de dados históricos (23.2 TB) pode proporcionar uma base rica para treinamento dos modelos de IA, aumentando a precisão das análises e insights gerados.

Engajamento de stakeholders: O envolvimento ativo dos stakeholders, especialmente o Product Owner, Tech Lead e Soft. Eng. Coordinator, pode acelerar o desenvolvimento, garantindo que as necessidades do cliente sejam atendidas de maneira eficiente.

Colaboração com clientes na geração de conteúdo: A possibilidade de envolver os clientes na geração de conteúdo com base nos insights da IA pode fortalecer as parcerias, resultando em uma oferta de conteúdo mais alinhada com as expectativas dos usuários.

Classificação eficiente de feedbacks: Utilizar técnicas de PLN para classificar automaticamente feedbacks dos usuários pode otimizar o processo de identificação de pontos de melhoria e preferências.

Integração com redes sociais: Se a IA puder integrar dados de redes sociais, como análise de tendências e compartilhamento de vídeos, pode proporcionar uma compreensão mais completa do comportamento do usuário e abrir novas oportunidades de engajamento.

Para garantir o sucesso de um projeto, é importante identificar e mitigar todos os riscos envolvidos no processo. No caso do projeto em questão, foram identificados alguns riscos. Abaixo, apresentamos maneiras de mitigar riscos mapeados:

Risco 1 : Realizar uma avaliação abrangente dos dados, identificando potenciais lacunas e inconsistências. Em seguida, implementar processos de limpeza e padronização para assegurar consistência.

Risco 2 : Estamos comprometidos em participar ativamente dos encontros e momentos de desenvolvimento. Priorizaremos a validação contínua com os stakeholders, garantindo alinhamento e ajustes necessários a cada sprint. Essa abordagem iterativa nos permitirá aprimorar gradualmente nossa solução, adaptando-a às demandas específicas do projeto e reduzindo a complexidade técnica ao longo do tempo.

Risco 3 : Implementar protocolos de criptografía robustos para proteger os dados sensíveis durante a coleta, armazenamento e transmissão. Além disso, estabelecer restrições de acesso, garantindo que apenas pessoal autorizado tenha permissão para lidar com informações sensíveis.

Risco 4 : Realizar reuniões regulares para discutir e esclarecer os requisitos do projeto com o grupo. Além disso, como comentado anteriormente, incentivar a participação ativa dos stakeholders na definição e validação contínua dos requisitos, vai nos garantir uma compreensão alinhada ao longo do ciclo de vida do projeto.

Risco 5 : Obter uma representação abrangente do conjunto de dados, implementar estratégias para ampliar a diversidade, como a inclusão de fontes adicionais de dados e a expansão da coleta para períodos específicos.

### Matriz de avaliação de valor Oceano Azul

Ferramenta estratégica projetada para auxiliar organizações a identificar e explorar novos mercados, livres de concorrência. Originária da necessidade de superar a intensa batalha por espaço no saturado "oceano vermelho" de competição, esta matriz oferece uma abordagem sistemática para criar valor inédito e abrir novos horizontes de mercado, enfatizando a importância de inovar além das fronteiras convencionais.


A construção da Matriz de Avaliação do Oceano Azul envolve a criação de um gráfico bidimensional, onde o eixo horizontal representa a gama de fatores que a indústria compete atualmente, e o eixo vertical indica o grau de oferta ou atração que a empresa oferece em cada um desses fatores. A matriz é construída em torno de quatro atributos principais (Elevar,Criar, Reduzir e Eliminar).


Através da análise e ajuste nesses quatro atributos, as empresas podem visualizar estrategicamente como modificar seu foco de competição, movendo-se de um oceano vermelho competitivo para um oceano azul de espaços de mercado inexplorados e repletos de oportunidades.


Para a construção da matriz, estamos considerando a Sambotech com a implementação futura do nosso futuro projeto e como ela se diferenciará da sua concorrência. Essa visão é baseada na visão de uma empresa que usa as plataformas para hospedagem e divulgação do seu trabalho.


#### REDUZIR:
Determinar os fatores que devem ser reduzidos bem abaixo do padrão da indústria. Isso envolve identificar aspectos que são superdimensionados nas ofertas atuais, permitindo simplificar produtos ou serviços.

**Velocidade de Aplicação:**
Em um mercado onde a oferta desse serviços é limitada e escassa, atrasar a entrega para ter maior qualidade pode vir a ser um diferencial competitivo significativo. Visto que o cliente não tem muitas opções no mercado com nossos benefícios e pode aceitar isso sem que nosso negócio perca muito valor.

**Dificuldade de Adoção:** 
Reduzir a complexidade e os obstáculos para novos usuários. Isso inclui melhorar a interface do usuário, simplificar o processo de onboarding e oferecer documentação e suporte mais claros. O que pode aumentar a base de usuários e reduzir a rotatividade, diferenciando dos nossos concorrentes.


#### ELIMINAR:
Identificar e descartar os fatores que a indústria toma como garantidos, mas que podem não ter mais valor ou relevância para o consumidor.

**Atendimento Virtual:**
Por se tratar de um software complexo e de uma venda B2B, nosso número de possíveis clientes são pequenos e exigem um atendimento personalizado, atributos que um chatbot não vai oferecer e nem gerar valor em relação a concorrência


**Custo de Implantação:**
Isso pode incluir oferecer uma versão mais enxuta da plataforma com a opção de upgrades pagos. Reduzir a barreira financeira de entrada pode atrair mais clientes, especialmente pequenos produtores de conteúdo ou startups.


#### LEVANTAR:
Reconhecer quais fatores devem ser elevados acima do padrão da indústria, melhorando elementos que agregam valor significativo ao cliente.

**Simplicidade Operacional:**
Elevando a simplicidade operacional, a plataforma pode tornar-se mais intuitiva e fácil de usar tanto para criadores de conteúdo quanto para os usuários finais. Isso implica em menos tempo e esforço necessário para realizar tarefas, como upload, edição e consumo de vídeos. Melhorando a usabilidade, espera-se aumentar a retenção de usuários e atrair novos criadores de conteúdo, oferecendo uma experiência sem fricções.

**Customização:**
Aumentando a capacidade de customização, a plataforma pode oferecer aos usuários uma experiência mais pessoal e relevante. Isso pode incluir desde interfaces personalizáveis até recomendações de conteúdo adaptadas aos interesses e ao histórico de visualização de cada usuário. Ao proporcionar uma experiência mais alinhada às preferências individuais, a plataforma pode melhorar o engajamento e a satisfação dos usuários.

**Custo de Manutenção:**
Ao elevar o foco no custo de manutenção, busca-se otimizar os recursos e a eficiência operacional, reduzindo despesas de longo prazo associadas à manutenção da plataforma. Isso pode ser alcançado por meio da adoção de tecnologias mais eficientes ou processos automatizados, garantindo sustentabilidade financeira e permitindo que investimentos sejam realocados para inovação e melhorias na plataforma.


#### CRIAR: 
Identificar e criar novos fatores que a indústria nunca ofereceu, introduzindo elementos inovadores que abrem novos espaços no mercado.

**Pesquisas personalizadas via chatbot:**
A introdução de pesquisas personalizadas via chatbot pode aumentar significativamente a interação e o engajamento dos usuários com a plataforma. Este atributo não só melhora a experiência do usuário ao proporcionar respostas rápidas e personalizadas às suas dúvidas, mas também coleta dados valiosos sobre preferências e comportamentos de consumo, permitindo aprimorar a oferta de conteúdo de forma alinhada às expectativas dos usuários.

**PLN para resumir conteúdos e criar sumários:** 
A criação de sumários e resumos de vídeos usando Processamento de Linguagem Natural (PLN) oferece um valor único ao permitir que os usuários compreendam rapidamente o conteúdo dos vídeos antes de decidir assistir. Isso não apenas melhora a acessibilidade e a eficiência da busca por conteúdo relevante, mas também pode aumentar a satisfação do usuário ao poupar tempo, oferecendo uma visão geral do conteúdo disponível.

### Análise Financeira

Nesta seção, o objetivo é esclarecer e evidenciar todo o processo de estimativa de custos deste projeto. Para isso, considerou-se o custo com salário da equipe utilizado para desenvolvimento da solução, custos relacionados à estrutura utilizada em nuvem, através dos serviços da AWS e salário da mesma equipe para manutenção do produto. Vale ressaltar que custos como Energia elétrica, internet e capacitação dos funcionários não serão considerados, dado que são custos já previstos independentemente do projeto.

#### Desenvolvimento

Durante o período de desenvolvimento da solução, estimou-se com base no site Glassdoor os salários de Product Owner(PO), Engenheiro de Software e Desenvolvedor. Considerando uma equipe com um PO, um Engenheiro de Software e seis desenvolvedores, obtem-se:

| Cargo                               | Quantidade | Salário             | Total            |
|----------------------------|---------------|----------------| -------------------|
| Product Owner                | 1                   | R$  11.500,00 | R$  11.500,00     |
| Engenheiro de Software | 1                   | R$   11.000,00 | R$  11.000,00     |
| Desenvolvedor                |  5                  | R$    3.400,00 | R$  17.000,00     | 
| **Total Mensal**              | --                  | --                    | **R$ 39.500,00** |

Dado que o tempo de desenvolvimento é de 10 semanas (2 meses e meio), infere-se um valor estimado de **R$ 98.750,00**.

#### Manutenção

Para garantir a manutenção do produto, considerou-se o custo com estrutura do software em Cloud e uma fração de 10% do salário da mesma equipe responsável pelo desenvolvimento, isso se justifica pela estimativa de que esses funcionários despenderão essa mesma fatia do tempo de trabalho com o monitoramento do produto.

Para isso, através de estimativa com a Calculadora de Preços da AWS, obtém-se:


![Image](https://github.com/Inteli-College/2024-T0006-ES07-G01/assets/140438205/30678f15-1858-4b3d-8ed9-9b69c29b8152)

(Para simulação, considerou-se todos os atributos com valor médio, dado que na Sprint 1 não é possível afirmar com maior precisão informações como: tempo de requisição, memória alocada, tipo e quantidade das instâncias, entre outros. Posteriormente, essa seção será atualizada com maior precisão.)

Além disso, temos o custo de 10% do salário da equipe estimado em R$ 3.950,00, totalizando então um custo de **R$ 4.157,82** por mês.





## Entendimento do Design

No capítulo de Usexr Experience ,focamos na essência do projeto, destacando a categorização e e separação dos videos em tags. Fazemos isso com o objetivo de otimizar a experiência dos usuários de forma fluída, identificando atributos-chave para redução, eliminação, aumento e criação. 
Buscamos assegurar que as interações dos usuários seja única e atenda as expectativas, melhorando a experiência do usuário.

### Estudo do Usuário

O usuário do sistema, será principalmente composto por clientes da Sambatech que geram e consomem conteúdo na plataforma de vídeos. Estes usuários podem ser categorizados em dois grupos principais:
**Criadores de Conteúdo:**
Este grupo inclui empresas e indivíduos que utilizam a plataforma da Sambatech para hospedar e compartilhar seus vídeos. Eles estão interessados em entender melhor o engajamento do público com seus vídeos, quais conteúdos são mais assistidos, e os momentos específicos dentro dos vídeos que capturam mais atenção. O objetivo deles é otimizar a criação de conteúdo para aumentar a retenção de usuários e o tempo de visualização.
**Espectadores:**
Usuários que consomem o conteúdo disponível na plataforma. Eles procuram conteúdos que atendam aos seus interesses e preferências. O comportamento de visualização, preferências, e feedback desses usuários são cruciais para gerar insights que ajudarão a melhorar a oferta de conteúdo e a experiência geral na plataforma.

Para ambos os grupos, o projeto visa utilizar a inteligência artificial para analisar o perfil de consumo de vídeos, identificando os vídeos mais assistidos e os momentos de maior engajamento para fornecer insights valiosos que possam ser udtilizados para melhorar a produção de conteúdo e a experiência do usuário na plataforma.

#### Necessidades e Objetivos dos Usuários
Criadores de Conteúdo:
- Necessitam de ferramentas que permitam analisar o engajamento com seus vídeos detalhadamente para entender quais conteúdos são mais eficazes em reter a atenção dos espectadores.
- Objetivam maximizar o alcance e a retenção de audiência, além de otimizar a produção de conteúdo baseando-se em insights concretos sobre preferências e comportamentos dos espectadores.

Espectadores:
- Necessitam de uma plataforma que ofereça conteúdo relevante e de fácil acesso, com recomendações personalizadas que correspondam a seus interesses e preferências.
- Buscam uma experiência de usuário fluida e intuitiva, que permita encontrar e consumir conteúdo sem dificuldades.

#### Preferências
Criadores de Conteúdo:
- Preferem interfaces claras e relatórios detalhados que facilitem a interpretação de dados analíticos.
- Valorizam insights sobre tendências de consumo e feedback específico sobre os elementos dos vídeos que mais engajam os espectadores.

Espectadores:
- Tendem a preferir plataformas que ofereçam conteúdo diversificado e alinhado com seus interesses pessoais.
- Preferem interfaces amigáveis e mecanismos eficientes de busca e recomendação de conteúdo.

#### Habilidades e Limitações
Criadores de Conteúdo:
- Possuem variados graus de habilidade técnica, desde criadores amadores até profissionais com recursos de produção avançados.
- Algumas limitações podem incluir a falta de conhecimento em análise de dados e otimização de conteúdo para engajamento digital.

Espectadores:
- As habilidades podem variar amplamente, com alguns usuários sendo muito adeptos à tecnologia enquanto outros podem ter dificuldades com interfaces complexas.
- Limitações incluem barreiras de acessibilidade para usuários com deficiências visuais, auditivas ou motoras.

#### Contexto de Uso
Criadores de Conteúdo:
- Operam em ambientes profissionais e casuais, utilizando a plataforma para fins comerciais, educacionais, ou de entretenimento.
- Utilizam a plataforma principalmente através de computadores, necessitando de funcionalidades robustas para upload e gerenciamento de conteúdo.

Espectadores:
- Consomem conteúdo em diversos contextos, incluindo em casa, no trabalho, ou em trânsito, usando uma variedade de dispositivos como smartphones, tablets, e computadores.
- O contexto de uso pode influenciar as preferências de conteúdo, por exemplo, vídeos curtos para consumo rápido em trânsito ou conteúdos longos para visualização em casa.

#### PERSONAS
Criadores de Conteúdo:
<img src="/assets/persona1.png" alt="Persona 1" title="Persona 1" width="1148">

Espectadores:
<img src="/assets/persona2.png" alt="Persona 2" title="Persona 2" width="1148">

### Proposta de UX para o sistema 

1. Estudo sobre o Usuário do Sistema:
- Conduziremos pesquisas detalhadas juntamente aos stakeholders do projeto para compreender as necessidades, preferências e contextos de uso dos criadores de conteúdo da plataforma. Identificaremos seus objetivos ao analisar o engajamento de vídeos, considerando diferentes perfis e níveis de experiência.

2. Experiências que o Usuário Deverá Passar ao Utilizar o Sistema:
- Definiremos uma jornada do usuário centrada na análise de engajamento, desde a entrada na plataforma até a aplicação de ajustes no conteúdo. Consideraremos pontos de contato importantes, como a visualização de métricas, segmentação de dados, revisão de sugestões e registro de análises. Garantiremos uma experiência fluida, eficiente e agradável.

3. Proposta de UX para o Sistema:
- Desenvolveremos interfaces intuitivas, acessíveis e esteticamente agradáveis, utilizando um design responsivo. Implementaremos uma navegação simplificada, destacando as principais funcionalidades de análise de engajamento. Utilizaremos elementos visuais claros para feedback instantâneo e incorporaremos personalização, permitindo aos usuários adaptar a interface conforme suas preferências.

4. Pilha de Tecnologias para Implementar a Proposta de UX:
- Consideraremos as seguintes tecnologias: Plataforma web para acessibilidade global e flexibilidade.

5. Linguagens de Programação:
- HTML, CSS, JavaScript para a construção de interfaces responsivas e interativas.
- Python para integrações e processamento eficiente de dados.

6. Frameworks e Bibliotecas:
- Utilizaremos frameworks web modernos, como React ou Vue.js, para desenvolvimento ágil da interface.
Possivelmente, frameworks Python como Flask ou Django para a camada de back-end.

7. Integrações:
- Integração com serviços de análise de vídeo e APIs da plataforma Samba Vídeos para garantir a consistência dos dados.

8. Armazenamento de Dados:
- Banco de dados escalável para armazenamento eficiente dos dados, considerando soluções como PostgreSQL ou MongoDB.


## Entendimento da Arquitetura do Sistema

### Introdução:

Este capítulo tem como objetivo fornecer uma visão abrangente da arquitetura do sistema proposto, apresentando seus principais componentes e as interações entre eles. O documento busca atender às diretrizes estabelecidas, incluindo a elaboração de um desenho do sistema, a proposição de agrupamento de componentes em pacotes, a indicação das interações entre os elementos e a abrangência dos requisitos funcionais e não funcionais do projeto.

### Descrição do Orquestrador

No que diz respeito ao projeto realizado para a SambaTech, o componente orquestrador desempenhará um papel fundamental na coordenação e na gestão das diversas etapas do processo de análise de dados e geração de insights. Este componente será responsável por garantir a integração eficiente entre os diferentes sistemas e recursos envolvidos, permitindo a execução fluida e eficaz das tarefas necessárias para alcançar os objetivos do projeto.

O componente orquestrador deste projeto atuará como gerenciador por trás das operações, supervisionando as seguintes atividades:

 - Comunicação com o componente de Speech-to-Text (STT):
O orquestrador será responsável por enviar solicitações HTTP ao componente de Speech-to-Text para processar a transcrição dos áudios dos vídeos em texto. Essas solicitações serão feitas de acordo com as necessidades do projeto, como transcrever comentários de usuários em texto para análise posterior.

 - Interação com o componente de Processamento de Linguagem Natural (NLP):
Após a transcrição dos áudios em texto, o orquestrador coordenará a comunicação com o componente de Processamento de Linguagem Natural para realizar análises mais avançadas, como identificar sentimentos expressos nos comentários dos usuários, extrair tópicos discutidos nos vídeos, ou identificar palavras-chave relevantes para a categorização de conteúdo.
 - Conexão com o banco de dados na AWS:
Além disso, o componente orquestrador será responsável por gerenciar as interações com o banco de dados na AWS, onde os dados coletados e processados serão armazenados. Ele coordenará a escrita e leitura de dados no banco de dados, garantindo a integridade e segurança dos dados.
 - Coordenação geral do fluxo de trabalho:
Além das interações específicas com os componentes individuais, o orquestrador também supervisionará o fluxo de trabalho geral do projeto, garantindo que cada etapa seja executada na ordem correta e que os resultados de uma etapa sejam passados adequadamente para a próxima.
Portanto, o componente orquestrador funcionará como um ponto central de controle e coordenação, garantindo que todas as partes do projeto trabalhem harmoniosamente juntas para alcançar os objetivos definidos.

### Desenho do Sistema

**Link:**
https://miro.com/welcomeonboard/OTYxZ09BdFpqcm1Vak5GRDRIQThaSTZ5dFlKdjA5dUdhSWEzcGdjaEpuQXhrZWdvY04wNHVyeUtaZEpxQ21GTnwzNDU4NzY0NTMxMjY2Njk3NTczfDI=?share_link_id=124995935214

![image](https://github.com/Inteli-College/2024-T0006-ES07-G01/assets/110630427/fa7e1729-73a8-4209-8a76-33f8040ad568)


**Descrição Textual:**


1. Recebimento do Vídeo pelo Orquestrador
O fluxo inicia com o componente orquestrador, que serve como o ponto de entrada para os vídeos fornecidos pelos usuários.


2. Transcrição de Áudio (Speech-to-Text)
Após o recebimento do vídeo, o orquestrador encaminha o arquivo para o componente de Speech-to-Text. Este componente utiliza tecnologias de reconhecimento de voz, como as fornecidas pela plataforma da IBM, para converter o áudio do vídeo em texto.


3. Processamento de Linguagem Natural (PLN)
O texto gerado pela transcrição de áudio é então enviado de volta ao orquestrador, que por sua vez, o encaminha para o componente de PLN. Este componente é composto por dois pacotes principais: o pipeline de PLN e o sumarizador. O pipeline de PLN,gera um resumo do conteúdo do vídeo, identificando temas centrais, palavras-chave e possíveis categorias.


4. Armazenamento e Categorização
Com o texto analisado e as informações relevantes extraídas, o orquestrador procede para salvar os resultados no banco de dados. Esta etapa envolve armazenar as tags, palavras-chave, categorias e o resumo do vídeo, tornando essas informações facilmente acessíveis e pesquisáveis para futura referência.


5. Retorno de Informações ao Usuário
Por fim, o sistema disponibiliza as tags, palavras-chave e categorias identificadas para o usuário, permitindo uma gestão eficaz do conteúdo de vídeo. Esta funcionalidade não apenas melhora a acessibilidade e a organização dos vídeos na plataforma, mas também potencializa a descoberta de conteúdo pelos usuários finais.


Forma de Comunicação entre o Orquestrador e o Banco de Dados
A comunicação entre o orquestrador e o banco de dados é um aspecto crucial desta arquitetura. Geralmente, essa comunicação é realizada através de chamadas de API, utilizando protocolos como HTTP/HTTPS para segurança. Os dados são tipicamente formatados em JSON, facilitando a interoperabilidade e a manipulação dos dados entre os diferentes componentes e linguagens de programação envolvidas.

### Componentes

----- Outros componentes -------

#### Componente PLN

Esse componente tem o objetivo de receber um texto, imaginando a transcrição de um vídeo, e ser capaz de categorizá-lo, ou seja, o serviço busca identificar quais os temas retratados no texto, através da API do ChatGPT, um dos principais modelos de linguagem natural existentes, otimizada por Engenharia de Prompt, a fim de que o serviço tenha resposta de altíssima acurácia e baixo custo.

Para facilitar o entendimento do componente, vamos exemplificar a sua aplicabilidade e visualizar o valor entregue:
A SambaTech produziu mais de 100 vídeos que consistem em entrevistas e conversas entre grandes empresários e inovadores. É lógico imaginar que diversos temas foram abordados, como estratégias de negócios, conceitos de Macro-Economia, e diversas tecnologias emergentes (IA, BlockChain, entre outros).Agora, com todos esses vídeos, a SambaTech quer ser capaz de armazenar esses vídeos junto aos temas abordados no mesmo.

**Problemática:** Ao categorizar esses vídeos manualmente, teremos um custo financeiro e de tempo consideravelmente alto, dada a necessidade do indivíduo ter de ouvir o podcast ou ler a transcrição inteira e ir anotando os temas abordados. A exemplo da SuperLesson (empresa apresentada na aula de Negócios), para realizar a revisão manual de uma videoaula de 2 horas, são gastos por volta de 3 horas para garantir uma boa acurácia. Podemos inferir então que, tratando-se de escala, a categorização manual é muito cara, seja financeiramente quanto por tempo.

**Valor agregado:** Ao utilizar o serviço, podemos estimar um custo financeiro seguindo o seguinte raciocínio:
Dada a média de 100 palavras por minuto, um vídeo do podcast com 30 minutos, apresentará algo em torno 30.000 palavras. Usando a média de 1,35 tokens por palavra, segundo a tokenização da OpenAI, podemos estimar 40.500 tokens. Agora, partimos do valor atual do token de input para o modelo 3.5-turbo, dado o valor de $ 0,001 / mil tokens, imagina-se o incrível custo de $ 0,04, algo em torno de R$ 0,2. Soma-se então uma resposta com 200 tokens, contendo as categorias identificadas pela API do ChatGPT a um valor de $ 0,003 / mil tokens, significando um valor de output com $ 0,0006 ou R$ 0,003. Finalizando então, um custo de R$ 0,2003 para a categorização completa do vídeo.

Além do valor financeiro imensamente menor, ressalta-se também o tempo para a conclusão do serviço. Como citado acima, podemos imaginar que um podcast de 30 minutos gaste 45 minutos para ser perfeitamente categorizado. Com a utilização do serviço, é imaginado que a resposta da requisição com as categorias demore entre 2 a 10 segundos. 

Tal feito permite a escalabilidade da categorização de diversos vídeos, com um valor acessível e tempo agradável.

### Componente de Broker Textos

O componente de Broker Textos atua como uma ponte essencial entre a transcrição de áudio, o PLN  (processamento de linguagem natural) e a sumarização de texto, desempenhando um papel integral na organização e extração de informações relevantes a partir do conteúdo do vídeo:

1. **Speech to Text (STT) com Serviço IBM:**
   - Responsável por converter o áudio do vídeo em texto.
   - Utiliza um serviço da IBM para realizar a transcrição do conteúdo falado no vídeo.

2. **Processo de PLN (Processamento de Linguagem Natural) com Python:**
   - Após a transcrição, o texto é submetido a um processo de PLN utilizando Python.
   - Uma biblioteca específica é empregada para dividir o áudio completo do vídeo em vários pedaços.
   - São realizadas análises, como identificação de palavras-chave, compreensão gramatical e reconhecimento de entidades, usando técnicas de processamento de linguagem natural..

3. **Sumarização com ChatGPT:**
   - Durante a fase de sumarização, o texto processado é dividido em categorias.
   - O componente utiliza o modelo de linguagem ChatGPT para realizar a sumarização, que é a geração de resumos concisos e informativos do conteúdo textual.
   - O texto é analisado e resumido de acordo com categorias específicas, identificadas durante o processo de PLN.

4. **Divisão em Categorias:**
   - Na etapa final, o texto sumarizado é dividido em categorias relevantes.

Pretendemos utilizar as seguintes bibliotecas: 
   - **Speech to Text (STT):**
     - IBM Watson Speech to Text API (usada no seu caso).
     - Google Cloud Speech-to-Text API.
     - Microsoft Azure Speech Service.

### componente de Broker Voz

O componente de Broker Voz desempenha um papel vital no processamento de áudio na sua solução. Vamos detalhar suas principais funcionalidades e sugerir bibliotecas recomendadas para Python:

1. **Speech to Text (STT) com Serviço IBM:**
   - Converte o áudio do vídeo em texto por meio de um serviço da IBM.

2. **Processamento de Linguagem Natural (PLN) com Python:**
   - Utiliza uma biblioteca Python para dividir o áudio do vídeo em várias partes.

   - **Processamento de Linguagem Natural (PLN) com Python:**
     - NLTK (Natural Language Toolkit): Para tokenização, análise gramatical e outras tarefas básicas.
     - SpaCy: Oferece recursos avançados de PLN, incluindo análise de entidades.
     - Gensim: Útil para modelagem de tópicos e sumarização de texto.

3. **Sumarização com ChatGPT:**
   - Divide o texto em categorias usando o modelo ChatGPT.

**Nota:** Certifique-se de instalar as bibliotecas necessárias usando ferramentas como pip. Exemplo: `pip install ibm-watson nltk spacy gensim`.

O componente de Broker Voz desempenha um papel integrado, permitindo a transição suave do áudio para o texto, segmentação do conteúdo e, finalmente, a sumarização em categorias específicas.

Pretendemos utilizar as seguintes bibliotecas: 
   - **Speech to Text (STT):**
     - IBM Watson Speech to Text API (usada no seu caso).
     - Google Cloud Speech-to-Text API.
     - Microsoft Azure Speech Service.
    

## Experiências que o usuário deverá vivenciar ao utilizar o sistema.

1. **Postagem do Vídeo:**
   - O usuário inicia a experiência postando um vídeo na plataforma da Sambotech.

2. **Acompanhamento do Status:**
   - Ao longo de todo o processo de categorização do vídeo, o usuário terá a oportunidade de acompanhar o status das atividades em andamento. Mensagens informativas são fornecidas para manter o usuário constantemente atualizado sobre cada etapa do processo. Por exemplo, durante a conversão de áudio para texto, o usuário receberá a mensagem "O áudio do seu vídeo está sendo convertido em texto".

3. **Speech-to-Text (Conversão de Áudio para Texto):**
   - O sistema utiliza um serviço da IBM para converter o áudio do vídeo em texto, enquanto o usuário é informado sobre o status dessa atividade.

4. **Processamento de Linguagem Natural (PLN) com Python:**
   - O texto resultante é processado utilizando uma biblioteca em Python, segmentando o áudio em vários pedaços para análise mais detalhada.

5. **Divisão do Texto em Categorias:**
   - O texto é dividido em categorias relevantes, proporcionando uma organização eficiente das informações. O usuário pode acompanhar esse processo em tempo real.

6. **Sumarização com ChatGPT:**
   - O texto segmentado é enviado para o modelo ChatGPT para realizar a sumarização. O usuário é mantido informado sobre o andamento dessa etapa.

7. **Apresentação dos Resultados Sumarizados:**
   - Os resultados sumarizados, organizados por categorias, são apresentados ao usuário. Este é notificado quando a sumarização é concluída, podendo avaliar a qualidade da categorização.

8. **Feedback do Usuário:**
   - O sistema fornece uma interface para que o usuário forneça feedback sobre a qualidade da sumarização, bem como sobre todo o processo. Isso pode contribuir para melhorias contínuas.

9. **Ajustes:**
   - Caso o usuário não fique satisfeito com os resultado do processo esse poderá alterar manualmente de acordo com suas preferências

10. **Pesquisas:**
-Após o processamento dos vídeos, o usuário terá um motor de busca mais eficiente, além de um melhor gerencimento dos seus conteúdos

---------------- Outros componentes -------------------------

### Requisitos Funcionais

#### Requisito Funcional 1

**Caso de Uso**: Transcrição de Áudio em Texto de Vídeos

**Descrição**: O sistema automatiza a transcrição do áudio presente nos vídeos para texto, permitindo a análise e classificação do conteúdo. Esta funcionalidade possibilita identificar tópicos, palavras-chave e sentimentos expressos, contribuindo para a compreensão do engajamento do público e otimização da produção de conteúdo.

**Atores**: Administrador da Plataforma, Criador de Conteúdo

**Fluxo Principal**:

O Criador de Conteúdo seleciona o vídeo que deseja transcrever a partir da biblioteca da plataforma.
O sistema processa o áudio do vídeo selecionado, realizando a transcrição de áudio para texto.
Após a transcrição, o texto estará pronto para ser analisado pelo sistema para identificar tópicos principais, palavras-chave e o sentimento geral expresso.
O sistema armazena a transcrição realizada para consultas futuras.

**Exceções**:
Se o vídeo estiver em um formato não compatível com o sistema de transcrição, o Criador de Conteúdo receberá uma mensagem solicitando a conversão do vídeo para um formato suportado antes da transcrição.

#### Requisito Funcional 2

**Transcrição e Categorização Automatizada de Vídeos**

**Caso de Uso: Transcrição e Categorização Automatizada de Vídeos**

**Descrição:** O sistema transcreve automaticamente o áudio de vídeos, utilizando o serviço Speech to Text da IBM. Em seguida, emprega processamento de linguagem natural para dividir e analisar o texto, usando o ChatGPT para sumarização e categorização. Essa funcionalidade busca organizar e compreender o conteúdo dos vídeos de maneira eficiente.

**Ator:** Usuário responsável pelo envio de vídeos.

**Fluxo Principal:**

1. Usuários fazem upload de vídeos na plataforma Sambou.
2. O sistema transcreve automaticamente a fala nos vídeos usando o Speech to Text da IBM.
3. O texto transcrito é processado por uma pipeline de PLN em Python, com a ajuda do ChatGPT para sumarização e categorização.
4. O vídeo é categorizado com base no conteúdo e as informações relevantes são armazenadas no banco de dados.
5. O "Upload de Vídeo Orquestrador" coordena todo o processo, garantindo a integração eficiente.

**Exceções:**

- Em caso de indisponibilidade do serviço Speech to Text da IBM, os usuários são notificados sobre a impossibilidade de transcrição.
- Falhas na execução da pipeline de PLN geram notificações para os administradores, indicando a necessidade de correções.
- Se ChatGPT o estiver inacessíveis, o sistema deve adotar alternativas para a sumarização do conteúdo e/ou gera notificações para os administradores, indicando a necessidade de correções..

#### Requisito Funcional 3

**Requisito Funcional: Teste de Detecção e Alerta de Conteúdo Inadequado por Meio de Áudio**

**Caso de Uso: Teste de Detecção e Alerta de Conteúdo Inadequado por Meio de Áudio**

**Descrição:** A fim de validar a eficácia da funcionalidade de detecção automática de conteúdo inadequado nos vídeos, será realizado um teste específico. Este teste consiste em enviar intencionalmente um áudio contendo palavrões conhecidos para avaliar a capacidade do sistema em identificar e gerar alertas para a equipe de administração. O objetivo é garantir que o sistema seja sensível à presença de linguagem ofensiva e capaz de acionar notificações adequadas.

**Ator:** Administrador da Plataforma

**Fluxo Principal:**

1. Envio intencional de um áudio contendo palavrões conhecidos para o sistema.
2. O sistema analisa automaticamente o conteúdo do áudio em busca de elementos considerados inadequados, como linguagem ofensiva. Caso seja identificado conteúdo inadequado, o sistema gera um alerta automaticamente.
3. O Administrador da Plataforma recebe notificações sobre o conteúdo impróprio detectado.
4. O administrador revisa o conteúdo, toma ações adequadas, como remoção ou restrição, e implementa medidas preventivas para evitar recorrências.

**Exceções:**

- Se não houver detecção de conteúdo inadequado, o sistema continuará monitorando, mantendo a plataforma livre de materiais inapropriados.

### Requisitos Não Funcionais

#### RNF 1: Precisão da PLN

**Descrição:** A solução de PLN deve fornecer uma precisão mínima de 80% na identificação correta de tags e categorização de vídeos. Esta precisão é definida como a proporção de classificações e tags corretos em relação ao total de classificações e tags gerados pela PLN.

**Validação:** Selecionar uma amostra de vídeos com tags e categorias previamente definidas por especialistas no domínio. Processar estes vídeos através da PLN e comparar as tags e categorias geradas automaticamente com as definidas pelos especialistas.

**Critério de Aceitação:** Pelo menos 80% das tags e categorias atribuídas pela PLN devem coincidir com as definidas pelos especialistas.

#### RNF 2: Escalabilidade

**Descrição:** A solução de análise de perfil de consumo de vídeos com inteligência artificial deve ser capaz de adaptar-se e crescer em resposta a um aumento no volume de dados gerados pela plataforma e ao número de usuários acessando o sistema. Isso implica na capacidade de expandir recursos computacionais (como poder de processamento e armazenamento) e de rede de forma eficiente e econômica, sem que haja necessidade de reestruturar completamente o sistema ou sofrer degradação significativa no desempenho.

**Razão:** A Sambatech está operando em um ambiente dinâmico e competitivo, onde o volume de conteúdo e o número de usuários estão em constante crescimento. Para manter a competitividade e a capacidade de inovação, é crucial que a plataforma possa lidar com esse crescimento sem comprometer a qualidade do serviço. A escalabilidade permite que a plataforma suporte mais usuários e dados, garantindo a continuidade do negócio e a satisfação do usuário.

**Critérios de Aceitação:**
- Elasticidade Automática: O sistema deve ser capaz de ajustar automaticamente os recursos de computação em resposta a variações na demanda, aumentando recursos durante picos de carga e reduzindo durante períodos de baixa demanda.
- Modularidade: Os componentes do sistema devem ser projetados de maneira modular, permitindo que novas funcionalidades sejam adicionadas e escaladas independentemente sem afetar o restante do sistema.
- Performance Sob Escala: O sistema mantém ou melhora seu desempenho conforme a escala aumenta, verificável através de testes de carga que simulam diferentes cenários de uso, incluindo o crescimento esperado do número de usuários e do volume de dados.
- Eficiência de Custo: A escalabilidade não deve apenas ser técnica, mas também econômica, garantindo que o custo para escalar o sistema seja sustentável e justificável pelo valor gerado.

**Impacto:** A implementação eficaz da escalabilidade tem um impacto direto sobre a capacidade da Sambatech de crescer e se adaptar às mudanças do mercado e às necessidades dos usuários. Isso não apenas garante a satisfação contínua do usuário, mas também contribui para a sustentabilidade financeira da empresa ao permitir o crescimento do negócio sem interrupções ou custos proibitivos de manutenção e expansão da infraestrutura. A escalabilidade eficaz é fundamental para a inovação contínua e para a capacidade da Sambatech de responder rapidamente a oportunidades de mercado, mantendo a plataforma competitiva e relevante para criadores de conteúdo e espectadores.


#### RNF 3 :  Eficiência e desempenho

**Descrição:** A eficiência e o desempenho são de extrema importância para garantir uma análise ágil e satisfatória no engajamento de vídeos do nosso cliente. O sistema deve disponibilizar respostas rápidas, inferiores a 5 segundos, e processamentos eficientes das métricas, garantindo assim uma interação eficaz durante o fluxo principal de categorizar e criar tags de vídeos, a partir de seus conteúdos. 

**Critérios:**
- Tempo de resposta rápido: o sistema deve apresentar um tempo médio de resposta para exibição das métricas de engajamento em um tempo que seja considerado rápido, o que garante uma análise e navegação fluida durante a interação do usuário no processo de análise  de engajamento desses videos.
- Processamento eficiente de dados: durante a exibição dessas métricas de engajamento, o sistema deve ser otimizado para processar grandes conjuntos de dados de forma eficiente, mantendo um desempenho estável e sem erros em situações de alta demanda.


### Value Proposition 
**Link:** 
https://www.canva.com/design/DAF8GUzBXes/Sdqcnof5QlWPm1o6_BLACQ/edit?utm_content=DAF8GUzBXes&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton

O Value Proposition Canvas é uma ferramenta visual que auxilia na definição e inovação da proposta de valor de um produto ou serviço. Ele se divide em duas partes: o Segmento de Cliente, que identifica o público-alvo, suas necessidades e desejos, e a Proposta de Valor, que destaca os benefícios específicos oferecidos, diferenciais e razões para os clientes escolherem a oferta. Essa ferramenta ajuda empresas a alinharem melhor seus produtos aos clientes, identificarem oportunidades de inovação e diferenciarem-se da concorrência.

![Image](https://github.com/orgs/Inteli-College/projects/14/assets/110369271/f7e4fa7d-b0aa-428a-904c-e848347043c7)

# Sprint 2

## Documentação do Serviço de transcrição de áudio

### Configuração do Ambiente:

Antes de executar a aplicação, é necessário configurar as variáveis de ambiente. Crie um arquivo chamado `.env` na raiz do projeto e configure as seguintes variáveis:

```plaintext
IBM_API_KEY=sua_chave_de_api
IBM_URL=sua_url_do_servico
```
### Funcionalidades:

## 1. Upload de Vídeo
Endpoint para fazer upload de um vídeo e extrair o áudio em formato FLAC.

- **URL:** `/upload_video`
- **Método:** `POST`
- **Parâmetros:**
  - `video` (tipo: arquivo, descrição: Vídeo no formato MP4 para upload)

**Respostas:**

- **200 OK:**
  - **Mensagem:** Áudio do vídeo extraído e salvo em FLAC com sucesso.
  - **JSON:**
    ```json
    {
      "message": "Áudio do vídeo extraído e salvo em FLAC com sucesso",
      "flac_path": "caminho/do/arquivo.flac"
    }
    ```
- **400 Bad Request:**
  - **Mensagem:** Erro de requisição, nenhum vídeo enviado ou extensão de arquivo não permitida.
  - **JSON:**
    ```json
    {
      "error": "Nenhum vídeo enviado"
    }
    ```
    ```json
    {
      "error": "Extensão de arquivo não permitida"
    }
    ```

## 2. Transcrição de Áudio
Endpoint para realizar a transcrição de um arquivo de áudio.

- **URL:** `/transcribe_audio`
- **Método:** `POST`
- **Parâmetros:**
  - `audio` (tipo: arquivo, descrição: Arquivo de áudio para transcrição)

**Respostas:**

- **200 OK:**
  - **JSON:**
    ```json
    {
      "transcription_results": [
        {
          "text": "Texto transcrito",
          "confidence": 0.85
        },
        {
          "text": "Outro texto transcrito",
          "confidence": 0.75
        }
      ]
    }
    ```
- **400 Bad Request:**
  - **Mensagem:** Erro de requisição, nenhum áudio enviado.
  - **JSON:**
    ```json
    {
      "error": "Nenhum áudio enviado"
    }
    ```
- **500 Internal Server Error:**
  - **Mensagem:** Erro ao realizar a transcrição.
  - **JSON:**
    ```json
    {
      "error": "Erro ao realizar a transcrição: mensagem_de_erro"
    }
    ```

# Execução da Aplicação:

Siga os passos abaixo para executar a aplicação Flask:

### Instalação de Dependências:

Certifique-se de ter todas as dependências instaladas. Você pode instalá-las usando:

```
pip install -r requirements.txt
```

# Testes

Para executar os testes, utilize o seguinte comando:

```
pytest -s test_app.py
```


### Iniciando a API:
Para facilitar a execução da aplicação, um Dockerfile foi fornecido. Certifique-se de ter o Docker instalado e execute os seguintes passos:

Construa a imagem Docker:
```
docker build -t nome_da_imagem .
```
Execute o contêiner Docker:
```
docker run -p 3000:3000 nome_da_imagem
```
Isso iniciará a aplicação Flask dentro de um contêiner Docker.

### Acessando a Documentação no Swagger:
A aplicação utiliza o Swagger para documentação detalhada dos endpoints. Após iniciar a aplicação, abra um navegador e acesse o seguinte endereço:

```bash
http://127.0.0.1:3000/apidocs/
```

### Explorando os Endpoints no Swagger:
Na interface Swagger, explore todos os endpoints disponíveis, seus parâmetros e exemplos de resposta.

### Testando os Endpoints no Swagger:
Utilize a interface Swagger para testar os endpoints interativamente, fornecendo entradas e visualizando as respostas.

### Interrompendo a Aplicação:
Ao terminar de explorar a documentação e testar os endpoints, você pode interromper a execução da aplicação.

## Documentação do Serviço de Categorização de Vídeo
https://colab.research.google.com/drive/12EcwjFqGH9qSWczEBOzODNf2RWuM3Hp_?usp=sharing
### Introdução
O serviço de Categorização de Vídeo é uma parte crucial da nossa aplicação, por permitir uma melhor eficiência na busca de vídeos dentro da plataforma. Este serviço é responsável por classificar transcrições de áudio em texto em cinco categorias pré-definidas: Tecnologia, Empreendedorismo, Vendas, Estratégias e Liderança. A categorização é feita através de um processo que envolve a leitura de arquivos, tokenização, padronização em minúsculas, remoção de stop words, e contabilização de palavras-chave para atribuir a categoria mais relevante ao texto.

### 1. API para implementação da etapa de Categorização de Vídeo

Esse serviço não esta hospedado em nenhuma API e é um serviço disponibilizado no Colab, logo o texto a seguir é um exemplo do que pretendemos implementar na Sprint 3 de integração, podendo vir a sofrer alterações.

#### Endpoints e Métodos HTTP
- **Endpoint para Categorização**: `/api/v1/categorize`
  - **Método HTTP Aceito**: `POST`

#### Parâmetros de Entrada
- **Body da Requisição (JSON)**:
  - `file_path`: Caminho do arquivo TXT contendo a transcrição do vídeo a ser categorizado.

#### Respostas Esperadas
- **Código de Sucesso**: `200 OK`
  - **Body da Resposta (JSON)**:
    - `category`: Categoria atribuída à transcrição do vídeo (Tecnologia, Empreendedorismo, Vendas, Estratégias, Liderança).

- **Código de Erro**: `404 Not Found`
  - **Body da Resposta (JSON)**:
    - `error`: Mensagem de erro indicando que o arquivo não foi encontrado.

#### Exemplo de Requisição
```json
POST /api/v1/categorize
Content-Type: application/json

{
  "file_path": "/content/sample_data/OSSOCIOS.txt"
}

#### Exemplo de Resposta

200 OK
Content-Type: application/json

{
  "category": "Tecnologia"
}

```

### 2. Algoritmo de NLP utilizado e sua implementação

#### Algoritmo de NLP

Para a categorização de vídeos, utilizamos um algoritmo de NLP baseado na análise de frequência de palavras-chave específicas para cada categoria. Este método permite uma análise quantitativa do conteúdo textual, facilitando a atribuição precisa de categorias com base no vocabulário utilizado na transcrição.

#### Implementação

**Bibliotecas Utilizadas:**

Bibliotecas Utilizadas: Para a implementação do nosso serviço de categorização de vídeo, utilizamos várias bibliotecas Python devido às suas funcionalidades específicas e eficácia. A biblioteca NLTK (Natural Language Toolkit) é fundamental para o processamento de linguagem natural, permitindo a tokenização, remoção de stop words e outras funções de pré-processamento de texto. Além disso, fazemos uso da biblioteca pandas para manipulação e análise de dados, facilitando a organização dos textos e dos scores de categorização. A biblioteca numpy é empregada para operações matemáticas de alto nível, especialmente úteis na manipulação de arrays e na realização de cálculos numéricos eficientes. Por fim, utilizamos a biblioteca re (expressões regulares) para a busca e manipulação de strings, permitindo uma análise detalhada e a filtragem do texto. Essa combinação de bibliotecas oferece um conjunto robusto de ferramentas para o desenvolvimento do nosso serviço de categorização, garantindo precisão e eficiência.

**Passos para Configuração:**

1. Acessar um notebook Colab
2. Importação das bibliotecas necessárias
3. Download dos pacotes necessários: stopwords e punkt.
4. Preparação do texto: Tokenização, remoção de stop words, e padronização para letras minúsculas.


#### Exemplos de código

**Funções para PLN:**

![image](https://github.com/Inteli-College/2024-T0006-ES07-G01/assets/110630427/2f87c37d-dd28-4a05-a736-96aab35cdf2c)

**Chamadas da Função:**

![image](https://github.com/Inteli-College/2024-T0006-ES07-G01/assets/110630427/5ae62578-5d7c-4754-8ccf-6e96664881e2)

## Documentação do Serviço de Tagueamento de Vídeo

### Introdução
O serviço de tagueamento de vídeo é muito importante para a nossa plataforma, pois ele melhora o processo da busca de vídeos, trazendo resultados mais precisos. Esse serviço examina o texto transcrito dos vídeos e identifica todos os substantivos no texto, contando a quantidade de vezes que cada substantivo aparece no texto. A partir disso ele seleciona os 5 mais populares e define as tags. O processo inclui a leitura do texto, tokenização, eliminação de palavras irrelevantes (stop words) e identificação das palavras-chave (os substantivos) mais significativas para determinar as cinco melhores tags que representam o conteúdo do vídeo.

### 1. API para implementação da etapa de Tagueamento de Vídeo

Igual ao serviço de categorização, este serviço também não está hospedado em nenhuma API e é um serviço disponibilizado no Colab, logo o texto a seguir é um exemplo do que pretendemos implementar na Sprint 3 de integração, podendo vir a sofrer alterações.

#### Endpoints e Métodos HTTP
- **Endpoint para Tagueamento**: `/api/v1/tag`
  - **Método HTTP Aceito**: `POST`

#### Parâmetros de Entrada
- **Body da Requisição (JSON)**:
  - `file_path`: Caminho do arquivo TXT contendo a transcrição do vídeo a ser tagueado.

#### Respostas Esperadas
- **Código de Sucesso**: `200 OK`
  - **Body da Resposta (JSON)**:
    - `tags`: 5 tags atribuídas à transcrição do vídeo (Substantivos que mais aparecem).

- **Código de Erro**: `404 Not Found`
  - **Body da Resposta (JSON)**:
    - `error`: Mensagem de erro indicando que o arquivo não foi encontrado.

#### Exemplo de Requisição
```json
POST /api/v1/tag
Content-Type: application/json

{
  "file_path": "/content/sample_data/OSSOCIOS.txt"
}

#### Exemplo de Resposta

200 OK
Content-Type: application/json

{
  "tags": [‘substantivo1’, ‘substantivo2’, ‘substantivo3’, ‘substantivo4’, ‘substantivo5’]
}

```


## Documentação do Serviço de geração das descrições

### Configuração do Ambiente:

Antes de executar a aplicação, é necessário configurar as variáveis de ambiente. Crie um arquivo chamado `.env` na raiz do projeto e configure as seguintes variáveis:

```plaintext
OPENAI_API_KEY=sua_chave_de_api
```
### Funcionalidades:

## 1. Consumo da API da OpenAI
Endpoint para gerar as duas descrições através do modelo gpt-3.5-turbo.

- **URL:** `/get-desc`
- **Método:** `POST`
- **Parâmetros:**
  - `texto` (tipo: arquivo, descrição: Vídeo no formato MP4 para upload)

**Respostas:**

- **200 OK:**
  - **JSON:**
    ```json
    {
      "descCurta": "<Texto gerado pela API>",
      "descLonga": "<Texto gerado pela API>"
    }
    ```
Atualmente, não há tratamento para erros em tempo de execução.

# Execução do Servidor:

Siga os passos abaixo para executar o servidor Node:

### Instalação de Dependências:

Certifique-se de ter todas as dependências instaladas. Você pode instalá-las usando:

```
npm install
```

É necessário a existência do Node na máquina.

# Testes

Para executar os testes, utilize o seguinte comando:

```
npm test
```
Atualmente, o teste não contempla todos os cenários idealizados e tende a apresentar erro.


### Iniciando a API:
Para facilitar a execução da aplicação, siga os seguintes passos:

```
npm start
```
Mais configurações podem ser visualizados no arquivo package.json

### Acessando a Documentação no Swagger:
A aplicação utiliza o Swagger para documentação detalhada dos endpoints. Após iniciar a aplicação, abra um navegador e acesse o seguinte endereço:

```bash
http://127.0.0.1:5028/api-docs/
```

### Explorando os Endpoints no Swagger:
Na interface Swagger, explore o endpoint disponível, seu parâmetro e exemplos de resposta.

### Testando os Endpoints no Swagger:
Utilize a interface Swagger para testar o endpoint interativamente, fornecendo entradas e visualizando as respostas.

### Interrompendo a Aplicação:
Ao terminar de explorar a documentação e testar os endpoints, você pode interromper a execução da aplicação.

## Sprint 3


### Construção do Backend da Solução

### Documentação da Sprint 3

## Documentação do Backend (Orquestrador)

### Configuração do Ambiente:

Antes de executar a aplicação, é necessário configurar as variáveis de ambiente. Crie um arquivo chamado `.env` na raiz do projeto e configure as seguintes variáveis:

```plaintext
POSTGRES_DB=""
POSTGRES_HOST=""
POSTGRES_PASSWORD=
POSTGRES_PORT=
POSTGRES_USER=
DATABASE_URL=""


TRANSCRIPTION_URL=""
DESCRIPTIONS_URL=""
PRE_PROCESSING_URL=""
CATEGORIZATION_URL=""
TAGGING_URL=""
```

### Funcionalidades:

## 1. CRUD para a entidade User
Rota que permitem operações com essa entidade, sendo o "create", a única implementação até o momento.

- **URL:** `/user/signup`
- **Método:** `POST`
- **Parâmetros:**
  - `name` (tipo: string, descrição: nome explicativo sobre quem é o usuario)

**Respostas:**

- **200 OK:**

    ```
    
     "Usuário cadastrado com sucesso"

    ```

## 2. CRUD para a entidade Video
Rotas que permitem operações com essa entidade, sendo o "create" e o "update", as únicas implementações até o momento.

- **URL:** `/video`
- **Método:** `POST`
- **JSON:**
  - ```json
     {
          linkS3: string;
    
          usuario: {
            connect: {
              id: number,  onde `id` é a chave primária do usuário
            };
          };
     }
    ```

**Respostas:**

- **200 OK:**
 - **JSON**
```json
{
    id: number;
    linkS3: string;
    linkTranscricao: string;
    transcricaoProcessada: string[];
    categoria: string;
    tags: string[];
    descricaoCurta: string;
    descricaoLonga: string;
    usuarioId: number;
}
```

- **URL:** `/video/:id`
- **Método:** `PUT`
- **JSON:**
  No JSON abaixo, vale citar que todos os campos são opcionais, de modo que o CRUD, entenderá que somente os campos existente devem ser alterados.
  - ```json
     {
          linkS3: string;
          linkTranscricao: string;
          transcricaoProcessada: string[];
          categoria: string;
          tags: string[];
          descricaoCurta: string;
          descricaoLonga: string;
          usuarioId: number;
     }
    ```

**Respostas:**

- **200 OK:**
 - **JSON**
```json
{
    id: number;
    linkS3: string;
    linkTranscricao: string;
    transcricaoProcessada: string[];
    categoria: string;
    tags: string[];
    descricaoCurta: string;
    descricaoLonga: string;
    usuarioId: number;
}
```


## 3. Webhooks para cada Serviço
Rotas que permitem que os serviços informem ao Backend a conclusão dos respectivos processamentos. Tal lógica, permite que o Orquestrador não fique preso a handshakes das requisições, permitindo que ele possua um tempo de resposta (considerando a soma de todos os webhooks de um fluxo ideal) menor que 500 ms. Esse resultado demonstra que a implementação desejada de Mensageria, onde o Orquestrador funcionará como o consumidor da fila. Nessa fila, idealiza-se diversos tipos de mensagens, de modo que elas indiquem ao Orquestrador quais fluxos devem ocorrer em seguida, seja salvar informação X no Banco de Dados, seja a chamada dos próximos serviços do pipeline.

Ressalta-se que essa API contém rastreabilidade, gerando logs a cada evento de entrada e saída da API, ou seja, ao receber um webhook, um log será gerado, informando o id do usuário responsável pela requisição, de onde veio o webhook e timestamp do momento exato da requisição. Segue o seguinte exemplo:
```json
{
    "userId": 2,
    "from": "/pre-processing",
    "timestamp": 1710457119469
  }
```
Para o log de saída (Quando o Orquestrador chama um outro serviço), altera-se o  campo "from" para "to". Exemplo:

```json
{
    "userId": 2,
    "to": "/pre-processing",
    "timestamp": 1710457119469
  }
```

Vale lembrar que abaixo, percebe-se os contratos para os webhooks do Orquestrador, em três desses webhooks (SaveCompleted, TranscriptionCompleted e PreProcessingCompleted) há novas chamadas a outros serviços. Porém o contrato dessas requisições será documentado nos respectivos serviços.



- **URL:** `/webhook/saveCompleted`
- **Método:** `POST`
- **JSON:**
  - ```json
     {
          linkS3: string;
          id: number
     }
    ```

**Respostas:**

- **200 OK:**
 - **JSON**
```json
{ status: 'success' }
```

- **URL:** `/webhook/transcriptionCompleted`
- **Método:** `POST`
- **JSON:**
  - ```json
     {
          linkTranscricao: string;
          id: number
     }
    ```

**Respostas:**

- **200 OK:**
 - **JSON**
```json
{ status: 'success' }
```

- **URL:** `/webhook/preProcessingCompleted`
- **Método:** `POST`
- **JSON:**
  - ```json
     {
          transcricaoProcessada: string[];
          id: number
     }
    ```

**Respostas:**

- **200 OK:**
 - **JSON**
```json
{ status: 'success' }
```

- **URL:** `/webhook/descriptionsCompleted`
- **Método:** `POST`
- **JSON:**
  - ```json
     {
          id: number,
          descricaoCurta: string;
          descricaoLonga: string;
     }
    ```

**Respostas:**

- **200 OK:**
 - **JSON**
```json
{ status: 'success' }
```

- **URL:** `/webhook/categorizationCompleted`
- **Método:** `POST`
- **JSON:**
  - ```json
     {
          id: number,
          categoria: string;
     }
    ```

**Respostas:**

- **200 OK:**
 - **JSON**
```json
{ status: 'success' }
```

- **URL:** `/webhook/taggingCompleted`
- **Método:** `POST`
- **JSON:**
  - ```json
     {
          id: number,
          tags: string[];
     }
    ```

**Respostas:**

- **200 OK:**
 - **JSON**
```json
{ status: 'success' }
```


# Execução do Servidor:

Siga os passos abaixo para executar o servidor em Nest.js com Typescript:

### Instalação de Dependências:

Certifique-se de ter todas as dependências instaladas. Você pode instalá-las usando:

```
npm install
```

É necessário a existência do Node na máquina.

# Testes

Para executar os testes, utilize o seguinte comando:

```
npm test
```
Atualmente, o teste não contempla todos os cenários idealizados e tende a apresentar erro.


### Iniciando a API:
Para facilitar a execução da aplicação, siga os seguintes passos:

```
npm start
```
Mais configurações podem ser visualizados no arquivo package.json


## Documentação do Serviço de geração das descrições

### Configuração do Ambiente:

Antes de executar a aplicação, é necessário configurar as variáveis de ambiente. Crie um arquivo chamado `.env` na raiz do projeto e configure as seguintes variáveis:

```plaintext
OPENAI_API_KEY=sua_chave_de_api
```
### Funcionalidades:

## 1. Consumo da API da OpenAI
Endpoint para gerar as duas descrições através do modelo gpt-3.5-turbo.

- **URL:** `/get-desc`
- **Método:** `POST`
- **Parâmetros:**
  - `texto` (tipo: arquivo, descrição: Vídeo no formato MP4 para upload)

**Respostas:**

- **200 OK:**
  - **JSON:**
    ```json
    {
      "message": "Demanda recebida com sucesso"
    }
    ```
A resposta não contém o resultado do processamento, pois como idealizado na arquitetura da Solução, atualmente estamos utilizando webhooks para que o serviço responda à requisição do Orquestrador de forma rápida, em seguida, este serviço fará uma requisição ao Orquestrador seguindo o seguinte molde no body:

```json
{
     
     descCurta: descCurta,
     descLonga: descLonga,
      
}
```

# Execução do Servidor:

Siga os passos abaixo para executar o servidor Node:

### Instalação de Dependências:

Certifique-se de ter todas as dependências instaladas. Você pode instalá-las usando:

```
npm install
```

É necessário a existência do Node na máquina.

# Testes

Para executar os testes, utilize o seguinte comando:

```
npm test
```
Atualmente, o teste não contempla todos os cenários idealizados e tende a apresentar erro.


### Iniciando a API:
Para facilitar a execução da aplicação, siga os seguintes passos:

```
npm start
```
Mais configurações podem ser visualizados no arquivo package.json

### Acessando a Documentação no Swagger:
A aplicação utiliza o Swagger para documentação detalhada dos endpoints. Após iniciar a aplicação, abra um navegador e acesse o seguinte endereço:

```bash
http://127.0.0.1:5028/api-docs/
```

### Explorando os Endpoints no Swagger:
Na interface Swagger, explore o endpoint disponível, seu parâmetro e exemplos de resposta.

### Testando os Endpoints no Swagger:
Utilize a interface Swagger para testar o endpoint interativamente, fornecendo entradas e visualizando as respostas.

### Interrompendo a Aplicação:
Ao terminar de explorar a documentação e testar os endpoints, você pode interromper a execução da aplicação.

## Documentação do Serviço de Transcrição de Áudio

### Configuração do Ambiente:

Antes de executar a aplicação, é necessário configurar as variáveis de ambiente. Certifique-se de ter as seguintes variáveis de ambiente configuradas:

```plaintext
IBM_API_KEY=<sua_chave_de_api>
IBM_URL=<sua_url_do_servico>
AWS_ACCESS_KEY_ID=<seu_id_de_acesso_aws>
AWS_SECRET_ACCESS_KEY=<seu_secret_access_key_aws>
AWS_SESSION_TOKEN=<seu_token_de_sessao_aws>
BUCKET_NAME=<nome_do_seu_bucket_s3>
```

### Funcionalidades:

## 1. Upload de Vídeo

Endpoint para fazer upload de um vídeo e extrair o áudio em formato FLAC.

- **URL:** `/upload_video`
- **Método:** `POST`
- **Parâmetros:**
  - `video` (tipo: arquivo, descrição: Vídeo no formato MP4 para upload)

**Respostas:**

- **200 OK:**
  - **Mensagem:** Áudio do vídeo extraído e salvo em FLAC na S3, juntamente com o vídeo em MP4, com sucesso.
  - **JSON:**
    ```json
    {
      "message": "Áudio do vídeo extraído e salvo em FLAC na S3, juntamente com o vídeo em MP4, com sucesso.",
      "mp4_path_s3": "s3://<bucket_name>/videos/<video_filename>",
      "flac_path_s3": "s3://<bucket_name>/audios/<audio_filename>"
    }
    ```
- **400 Bad Request:**
  - **Mensagem:** Erro de requisição, nenhum vídeo enviado ou extensão de arquivo não permitida.
  - **JSON:**
    ```json
    {
      "error": "Nenhum vídeo enviado"
    }
    ```
    ```json
    {
      "error": "Extensão de arquivo não permitida"
    }
    ```

## 2. Transcrição de Áudio

Endpoint para realizar a transcrição de um arquivo de áudio.

- **URL:** `/transcribe_audio`
- **Método:** `POST`
- **Parâmetros:**
  - `audio_blob_name` (tipo: string, descrição: Caminho do arquivo de áudio no serviço de armazenamento)
  - `user_id` (tipo: string, descrição: ID do usuário associado ao áudio)

**Respostas:**

- **200 OK:**
  - **JSON:**
    ```json
    {
      "transcription_results": [
        {
          "text": "Texto transcrito",
          "confidence": 0.85
        },
        {
          "text": "Outro texto transcrito",
          "confidence": 0.75
        }
      ]
    }
    ```
- **400 Bad Request:**
  - **Mensagem:** Erro de requisição, nenhum caminho de áudio enviado.
  - **JSON:**
    ```json
    {
      "error": "Nenhum caminho de áudio enviado"
    }
    ```
- **500 Internal Server Error:**
  - **Mensagem:** Erro ao realizar a transcrição.
  - **JSON:**
    ```json
    {
      "error": "Erro ao realizar a transcrição: mensagem_de_erro"
    }
    ```

## Rastreabilidade por Logs

A aplicação registra eventos em um arquivo de log para fins de rastreabilidade. Cada log contém as seguintes informações:

- `user_id`: ID do usuário associado à ação.
- `service_name`: Nome do serviço chamado.
- `timestamp`: Data e hora em que a ação ocorreu.
- `processing_time`: Tempo necessário para processar a ação, em segundos.

Os logs são armazenados no arquivo `log.json` na raiz do projeto.

### Testes:

Para executar os testes, utilize o seguinte comando:

```
pytest -s test_app.py
```

Não se esqueça de instalar todas as dependências necessárias através do:

```
pip install -r requirements.txt
```

### Executando com Docker:

Para facilitar a execução da aplicação Flask, um Dockerfile foi fornecido. Certifique-se de ter o Docker instalado e siga os passos abaixo:

1. **Construa a imagem Docker:**

   Execute o seguinte comando no terminal para construir a imagem Docker:
   ```
   docker build -t nome_da_imagem .
   ```

   
Certifique-se de substituir `nome_da_imagem` pelo nome desejado para sua imagem Docker.

2. **Execute o contêiner Docker:**

    Após construir a imagem Docker, execute o seguinte comando para iniciar o contêiner Docker:

   ```
   docker run -p 3000:3000 nome_da_imagem
   ```

Isso iniciará a aplicação Flask dentro de um contêiner Docker, tornando-a acessível na porta 3000 do seu localhost.

Após seguir esses passos, a aplicação estará em execução dentro de um contêiner Docker e pronta para uso.

### Explorando a Documentação no Swagger:

A aplicação utiliza o Swagger para documentação detalhada dos endpoints. Após iniciar a aplicação, abra um navegador e acesse o seguinte endereço:

```
http://127.0.0.1:3000/apidocs/
```

### Interrompendo a Aplicação:

Ao terminar de explorar a documentação e testar os endpoints, você pode interromper a execução da aplicação.

# Documentação da Sprint 3: Serviço de Categorização de Vídeo

## Introdução

Durante a Sprint 3, evoluímos significativamente nosso serviço de Categorização de Vídeo. As implementações dessa fase focaram em otimizar a aplicação para um ambiente de produção real, melhorando a infraestrutura, escalabilidade, e rastreabilidade, além de introduzir novas funcionalidades.

## Alterações e Novas Funcionalidades

### Migração para Aplicação Flask em EC2 AWS

A principal mudança foi a transição do script de PLN para uma aplicação Flask operando em uma instância EC2 da AWS, marcando uma etapa para a integração e funcionamento contínuo em produção.

### Implementação de Webhooks

Implementamos webhooks para aprimorar a comunicação assíncrona com outros sistemas, permitindo que o serviço notifique automaticamente sistemas externos sobre a conclusão do processamento e a categoria atribuída.


### Logs em Formato JSON

Para facilitar a rastreabilidade e depuração do serviço, introduzimos um sistema de logs que registra eventos em formato JSON em um arquivo application.txt.


### Facilidade de Implantação com Docker

Com a criação de um Dockerfile, o processo de implantação tornou-se mais simples, minimizando problemas de configuração de ambiente.

## Detalhes Técnicos

### Endpoints e Métodos HTTP

#### Recepção de Transcrição

- **Endpoint**: `/receive_transcription`
- **Método HTTP**: `POST`
- **Descrição**: Recebe a transcrição do áudio em texto e inicia o processo de categorização.

### Estrutura dos Dados Recebidos

```json
{
  "id": "Identificador único da transcrição",
  "processedTranscription": "Texto da transcrição a ser categorizada"
}
 **Resposta Esperada:**
{
  "message": "Transcrição recebida, processamento iniciado."
}
```

### Funções Implementadas

#### process_transcription_and_notify(data):

Essa função é responsável por processar a transcrição recebida, categorizando-a e notificando o orquestrador sobre a conclusão do processamento.

**Parâmetros:** data (dict) contendo o ID da transcrição e o texto processado.

**Fluxo:**

Extrai o ID e o texto da transcrição.
Processa o texto para determinar a categoria.
Armazena o resultado.
Notifica o orquestrador sobre a conclusão, enviando a categoria determinada.

#### notify_return_response(transcription_id, categoria):

Após o processamento da transcrição, esta função notifica o orquestrador, enviando o ID da transcrição e a categoria atribuída.

**Parâmetros:** transcription_id (ID da transcrição), categoria (categoria determinada).
**Fluxo:**
Prepara a payload com o ID da transcrição e a categoria.
Envia uma requisição POST para o endpoint do orquestrador.
Registra o sucesso ou falha da notificação nos logs.
### Conclusão

Com as melhorias e novas funcionalidades introduzidas na Sprint 3, o serviço de Categorização de Vídeo está melhor preparado para sua integração em ambientes de produção. A migração para uma aplicação Flask, o uso de webhooks, aprimoramento dos logs, e a facilidade de implantação via Docker são avanços significativos para o projeto. Pela imagem abaixo podemos identificar os logs  o funcionamentos dos webhooks.

![image](https://github.com/Inteli-College/2024-T0006-ES07-G01/assets/110630427/257ab73e-297a-4487-bdad-d6e7de710e47)

# Documentação da API de Processamento de geração de tags:

## Introdução

A API de Processamento de Texto foi desenvolvida para realizar operações básicas de processamento de texto, como tokenização, contagem de frequência de palavras e identificação das palavras mais frequentes em um texto fornecido pelo usuário.

## Configuração do Ambiente

Certifique-se de ter as seguintes bibliotecas instaladas no ambiente de execução:

- Flask
- spaCy
- BeautifulSoup4

Você pode instalar as dependências necessárias executando o seguinte comando no terminal:

```bash
pip install flask spacy pandas beautifulsoup4
python -m spacy download pt_core_news_lg
```

## Funcionalidades

### 1. Processamento de Texto

#### Rota

- **URL:** `/api/processar_texto`
- **Método HTTP:** POST

#### Parâmetros

- **texto:** (string) O texto a ser processado.

#### Respostas

- **200 OK:**

<img width="839" alt="image" src="https://github.com/Inteli-College/2024-T0006-ES07-G01/assets/110369271/c81721e3-296c-4b16-8b10-42cff7954216">

  ```json
  {
      "result": "Processamento concluído com sucesso",
      "palavras_mais_frequentes": [
          ["buraco", 2],
          ["galáxias", 1],
          ["maioria", 1],
          ["conta", 1],
          ["conservação", 1]
      ]
  }

<img width="856" alt="image" src="https://github.com/Inteli-College/2024-T0006-ES07-G01/assets/110369271/7734b7f4-e55d-4db4-a368-fe1325e39f46">

  ```
- **400 Bad Request:**
  ```json
  {
      "error": "Falha ao processar o texto. Certifique-se de fornecer um texto válido."
  }
  ```

## Execução do Servidor

Para iniciar o servidor Flask, execute o seguinte comando no terminal dentro do diretório do projeto:

```bash
python run.py
```

<img width="487" alt="image" src="https://github.com/Inteli-College/2024-T0006-ES07-G01/assets/110369271/45a52eff-2548-42ad-a233-4c95a969a3f2">

Isso iniciará o servidor Flask, e você poderá acessar a API por meio das rotas definidas.

## Acessando a API via Postman

Após iniciar o servidor, você pode acessar a API usando o Postman ou qualquer outra ferramenta de cliente HTTP. Certifique-se de enviar uma solicitação POST para a rota `/api/processar_texto`, incluindo o texto a ser processado no corpo da solicitação.

## Considerações Finais

A API de Processamento de Texto oferece uma maneira simples e eficaz de realizar operações básicas de processamento de texto. Se precisar de mais informações ou assistência, consulte a documentação ou entre em contato com a equipe de desenvolvimento.

## Sprint 4

### Construção do Frontend da Solução

### Documentação da Sprint 4

### 1. Implementação do frontend com o framework ou biblioteca

O frontend da aplicação foi implementado utilizando a biblioteca Streamlit, que é uma ferramenta popular para a construção de interfaces de usuário em Python. Abaixo estão os principais pontos da implementação:

- Utilização do Streamlit para criar a interface de usuário.
- Uso de componentes como `st.title`, `st.file_uploader`, `st.button`, `st.success`, `st.spinner`, entre outros, para criar uma experiência interativa para o usuário.
- Utilização de CSS para estilizar elementos como o spinner de carregamento.

### 2. Testes do frontend implementado

Os testes do frontend foram realizados manualmente e automatizados. Para os testes manuais, foram realizados testes de usabilidade e de interface, garantindo que todos os elementos respondem corretamente às interações do usuário.

Para os testes automatizados, foi desenvolvido um script utilizando a biblioteca Selenium, que simula as interações do usuário e verifica se a aplicação se comporta conforme o esperado. O script realiza ações como selecionar um arquivo de vídeo, enviar o vídeo para a aplicação, aguardar o processamento e verificar se a mensagem de sucesso é exibida.

### 3. Integração do frontend com o backend implementado

O frontend foi integrado ao backend utilizando uma requisição HTTP para enviar o vídeo selecionado pelo usuário para o servidor. Foi utilizado o método POST para enviar os dados como um arquivo multipart/form-data, garantindo a transmissão eficiente dos dados.

Após o processamento do vídeo no backend, o frontend exibe as informações resultantes, como descrições, categoria e tags, para o usuário.

### 4. Deploy da solução

A solução foi implantada em um servidor AWS (Amazon Web Services). O backend foi hospedado em uma instância EC2, enquanto o frontend foi hospedado utilizando o próprio Streamlit, que permite implantar aplicativos diretamente em um servidor.

Para acessar a aplicação, os usuários podem visitar a URL do servidor onde a aplicação está implantada, por exemplo: http://ec2-35-168-145-26.compute-1.amazonaws.com:8501.

A integração contínua e a entrega contínua (CI/CD) foram configuradas para garantir que quaisquer alterações no código sejam automaticamente implantadas no servidor de produção, garantindo uma experiência contínua e confiável para os usuários.

# Teste do Frontend com Selenium

Este é um teste automatizado desenvolvido em Python usando a biblioteca Selenium para realizar o upload de um vídeo em um aplicativo Streamlit e verificar se a mensagem de sucesso é exibida corretamente.

## Configuração do Ambiente

Antes de executar o teste, é necessário garantir que o ambiente esteja configurado corretamente. Certifique-se de ter instalado as dependências.

```bash
pip install -r requirements.txt
```

Além disso, o ambiente do aplicativo Streamlit deve estar em execução na URL `http://localhost:8501`.

## Execução do Teste

Para executar o teste, basta rodar o script Python `test_video_upload.py`. O teste realiza as seguintes etapas:

1. Configura o WebDriver do Chrome.
2. Abre o aplicativo Streamlit no navegador.
3. Encontra o elemento de upload de vídeo.
4. Envia um arquivo de vídeo para o elemento de upload.
5. Aguarda 2 segundos.
6. Simula um clique na posição (418, 510) usando a biblioteca PyAutoGUI.
7. Aguarda a visibilidade da mensagem de sucesso por até 10 segundos.
8. Verifica se a mensagem de sucesso está sendo exibida corretamente.

<img width="526" alt="image" src="https://github.com/Inteli-College/2024-T0006-ES07-G01/assets/99328889/7d45f918-4705-4404-9515-5cd67e7a4536">


## Observações

- O teste foi desenvolvido utilizando a biblioteca PyAutoGUI para simular o clique do mouse na interface do usuário. Isso foi necessário devido a uma limitação na interação direta com elementos DOM do Streamlit pelo Selenium.
- Certifique-se de que o arquivo de vídeo de teste está localizado no diretório `video_teste` e tem o nome `video_teste.mp4`.
- Os tempos de espera e as coordenadas do clique podem precisar ser ajustados dependendo das características específicas do ambiente de teste.
- Ao finalizar o teste, o navegador será fechado automaticamente.




## Sprint 5

### Elaboração da Documentação Final do Projeto

### Custo de implementação da prova de conceito e estimativa de custo para a solução final:

No início do projeto, realizamos uma estimativa dos serviços necessários para o desenvolvimento do projeto, considerando os 2 meses e meio de duração previstos. Os serviços necessários seriam os seguintes:


| Quantidade | Profissões               | Valor total   |
|------------|--------------------------|---------------|
| 1          | Product Owner            | R$ 11.500,00 |
| 1          | Engenheiro de Software   | R$ 11.000,00 |
| 5          | Desenvolvedores estagiários | R$ 17.000,00 |
|            | **Total:**               | **R$ 39.500,00** |



Em relação ao uso da AWS, não foi estipulado um valor devido à incerteza sobre a quantidade de APIs que seriam criadas e alocadas ao serviço.

Após os 2 meses e meio de desenvolvimento, conseguimos estimar com maior precisão os gastos médios:

**Serviços variáveis:**

| Serviços                        | Valor total   |
|---------------------------------|---------------|
| Internet                        | R$ 200,00     |
| Manutenção de Api’s e outros   | Incluso nas atividades dos desenvolvedores |
| Serviços da IBM                 | R$ 600,00     |
| AWS EC2                         | R$ 800,00     |
| Product Owner                   | R$ 11.500,00  |
| Engenheiro de Software          | R$ 11.000,00  |
| 4 Desenvolvedores estagiários  | R$ 20.000,00  |
|                                 | **Total:**    | 
|                                 | **R$ 44.100,00** |


**Fixos:**

| Fixos       | Quantidades | Produtos     | Valor total  |
|-------------|-------------|--------------|--------------|
|             | 3           | Computadores | R$ 24.000,00 |


### Funcionalidades implementadas na prova de conceito:

Utilizando o Processamento de Linguagem Natural (PLN), a SambaTech oferecerá aos seus clientes um serviço automatizado para transcrição, tageamento e descrição de vídeos, reduzindo significativamente o tempo necessário para essas tarefas que hoje são feitas manualmente.

### Os requisitos funcionais e não funcionais do projeto devem estar compreendidos no sistema. Formato da entrega:

### Requisitos funcionais implementados:

1. Transcrição de Áudio em Texto de Vídeos:
   - Permite ao usuário inserir um vídeo para transcrição, fornecendo as cinco palavras mais frequentes encontradas no vídeo.
2. Transcrição e Categorização Automatizada de Vídeos:
   - Permite ao usuário receber a categorização do vídeo (assunto do vídeo) utilizando uma API que analisa a transcrição do vídeo.
3. Teste de Detecção e Alerta de Conteúdo Inadequado por Meio de Áudio (não implementado).

### Requisitos não funcionais:
1. Precisão da PLN:
   - O modelo entregue possui uma precisão de 80% nas tags e categorização.
2. Escalabilidade (implementação não confirmada).
3. Eficiência e desempenho:
   - A resposta é fornecida em tempo superior a 5 segundos.

### Análise financeira do projeto - deve ser informado o quanto o parceiro tem projetado para investir no projeto e quais são as projeções de custos e de receitas que o parceiro projeta ter relacionadas ao projeto (para o período de um ano):

Como não houve uma conversa específica sobre valores de investimento com a SambaTech, esta análise será baseada nos ganhos projetados para a SambaTech após a implementação do serviço.

Considerando os ganhos projetados para a SambaTech após a implementação do serviço, estimamos que os gastos médios serão de R$520.000,00 no período de um ano. A melhoria nos serviços deve aumentar a satisfação dos clientes existentes e facilitar a captação de novos clientes.



### Apresentação Final
